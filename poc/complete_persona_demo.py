#!/usr/bin/env python3
"""
Complete Persona System Demo
============================

Demonstrates the full persona system with:
- LLM text responses
- Image generation 
- Voice generation
- Self-identification capabilities
- Trigger-based lifecycle
"""

import asyncio
import os
from datetime import datetime
from persona_config import PersonaConfig
from llm_persona_firefly import LLMPersonaFirefly
from persona_image_generator import generate_persona_image_simple
from persona_voice_generator import generate_persona_voice_simple

async def complete_persona_demo():
    """Complete demonstration of all persona capabilities"""
    print("ğŸ­ Complete Persona System Demo")
    print("=" * 60)
    print(f"â° Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Check API key
    api_key = os.getenv("OPENAI_API_KEY")
    
    if api_key:
        print("ğŸ”‘ OpenAI API key found - using real APIs")
        print("ğŸ’° Using cost-optimized settings")
    else:
        print("âš ï¸  No API key - using mock responses")
        print("ğŸ’¡ Set OPENAI_API_KEY to use real APIs")
    
    # Create sample persona
    persona = PersonaConfig(
        name="Sarah Chen",
        age=35,
        race_ethnicity="asian",
        gender="female",
        education="graduate",
        location_type="urban",
        income="75k_100k",
        media_consumption="diverse",
        risk_tolerance="moderate",
        civic_engagement="high"
    )
    
    print(f"\nğŸ‘¤ Creating complete persona profile for: {persona.name}")
    print(f"   Demographics: {persona.age}yo {persona.race_ethnicity} {persona.gender}")
    print(f"   Background: {persona.education} education, {persona.location_type}, {persona.income}")
    
    try:
        # === STEP 1: Generate Persona Image ===
        print(f"\nğŸ¨ Step 1: Generating Profile Image")
        print("-" * 40)
        
        image_result = generate_persona_image_simple(persona, api_key)
        
        if image_result["success"]:
            print(f"âœ… Profile image generated!")
            print(f"ğŸ–¼ï¸  Image URL: {image_result['image_url']}")
            print(f"ğŸ“ Image prompt: {image_result['prompt']}")
            if image_result.get("model") == "dall-e-2":
                print(f"ğŸ’° Image cost: ~$0.02")
        else:
            print(f"âŒ Image generation failed: {image_result['error']}")
        
        # === STEP 2: Generate Persona Voice ===
        print(f"\nğŸ¤ Step 2: Generating Voice Sample")
        print("-" * 40)
        
        voice_result = generate_persona_voice_simple(persona, api_key)
        
        if voice_result["success"]:
            print(f"âœ… Voice sample generated!")
            print(f"ğŸµ Audio file: {voice_result['audio_path']}")
            print(f"ğŸ—£ï¸  Voice: {voice_result['voice_used']} - {voice_result['voice_characteristics']}")
            print(f"ğŸ“ Script preview: {voice_result['script_text'][:100]}...")
            if voice_result.get("model") == "tts-1":
                cost = len(voice_result['script_text']) * 0.000015
                print(f"ğŸ’° Voice cost: ~${cost:.4f}")
        else:
            print(f"âŒ Voice generation failed: {voice_result['error']}")
        
        # === STEP 3: Create Interactive Persona ===
        print(f"\nğŸ§  Step 3: Creating Interactive LLM Persona")
        print("-" * 40)
        
        firefly = LLMPersonaFirefly(persona, purpose="complete_demo")
        
        # Set API config if available
        if api_key:
            firefly.set_llm_config("openai", api_key)
        
        # Show self-identification capabilities
        print(f"ğŸ” Persona Self-Identification:")
        capabilities = firefly.describe_capabilities()
        print(f"   Available functions: {len(capabilities)}")
        
        self_desc = firefly.describe_self()
        print(f"   Agent type: {self_desc['agent_type']}")
        print(f"   Firefly ID: {self_desc['firefly_metadata']['firefly_id'][:8]}...")
        
        # === STEP 4: Interactive Demo Questions ===
        print(f"\nğŸ’¬ Step 4: Interactive Q&A Session")
        print("-" * 40)
        
        demo_questions = [
            "Tell me about your background and what's important to you.",
            "What's your opinion on remote work and technology in the workplace?",
            "How do you approach financial decisions and investments?",
            "What changes would you like to see in your community?"
        ]
        
        total_llm_cost = 0
        
        for i, question in enumerate(demo_questions, 1):
            print(f"\nğŸ“‹ Question {i}: {question}")
            
            is_final = (i == len(demo_questions))
            
            try:
                response = await firefly.glow({
                    "prompt": question,
                    "disappear": is_final  # Trigger disappear on last question
                })
                
                print(f"ğŸ¤– {persona.name}: {response['persona_response']}")
                
                # Track usage and cost
                if response.get("usage") and api_key:
                    usage = response["usage"]
                    if "input_tokens" in usage:
                        input_cost = usage.get("input_tokens", 0) * 0.00003
                        output_cost = usage.get("output_tokens", 0) * 0.00006
                        total_llm_cost += input_cost + output_cost
                        print(f"ğŸ“Š Tokens: {usage.get('input_tokens', 0)} in, {usage.get('output_tokens', 0)} out")
                
                if response.get("purpose_complete"):
                    print(f"âœ… Demo session completed - firefly disappeared")
                    break
                    
            except Exception as e:
                print(f"âŒ LLM interaction failed: {e}")
                if firefly.is_alive:
                    await firefly.disappear()
                break
        
        # === STEP 5: Summary ===
        print(f"\nğŸ¯ Demo Summary")
        print("=" * 60)
        print(f"âœ… Profile image: {'Generated' if image_result['success'] else 'Failed'}")
        print(f"âœ… Voice sample: {'Generated' if voice_result['success'] else 'Failed'}")
        print(f"âœ… LLM interaction: {len(demo_questions)} questions answered")
        print(f"âœ… Firefly lifecycle: Completed and cleaned up")
        
        if api_key:
            total_cost = 0.02 + (len(voice_result['script_text']) * 0.000015) + total_llm_cost
            print(f"\nğŸ’° Total estimated cost: ~${total_cost:.4f}")
            print(f"   â€¢ Image (DALL-E 2): ~$0.02")
            print(f"   â€¢ Voice (TTS-1): ~${len(voice_result['script_text']) * 0.000015:.4f}")
            print(f"   â€¢ LLM (GPT-4): ~${total_llm_cost:.4f}")
        
        print(f"\nğŸ“ Generated files:")
        if image_result['success']:
            print(f"   ğŸ–¼ï¸  {image_result['image_url']}")
        if voice_result['success']:
            print(f"   ğŸµ {voice_result['audio_path']}")
        
        print(f"\nğŸš€ Complete persona profile created for {persona.name}!")
        print("   Ready for market research, behavioral analysis, and user studies.")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()

async def quick_persona_creation(name: str, age: int, demographics: dict):
    """Quick function to create a complete persona profile"""
    print(f"\nâš¡ Quick Persona Creation: {name}")
    print("-" * 30)
    
    # Create persona config
    persona = PersonaConfig(
        name=name,
        age=age,
        **demographics
    )
    
    api_key = os.getenv("OPENAI_API_KEY")
    
    # Generate all assets
    tasks = []
    
    # Image generation
    print(f"ğŸ¨ Generating image...")
    image_result = generate_persona_image_simple(persona, api_key)
    
    # Voice generation
    print(f"ğŸ¤ Generating voice...")
    voice_result = generate_persona_voice_simple(persona, api_key)
    
    # Create firefly for capabilities
    firefly = LLMPersonaFirefly(persona, purpose="quick_creation")
    if api_key:
        firefly.set_llm_config("openai", api_key)
    
    print(f"âœ… {name} persona created!")
    print(f"   Image: {'âœ“' if image_result['success'] else 'âœ—'}")
    print(f"   Voice: {'âœ“' if voice_result['success'] else 'âœ—'}")
    print(f"   LLM: {'âœ“' if firefly else 'âœ—'}")
    
    return {
        "persona": persona,
        "image": image_result,
        "voice": voice_result,
        "firefly": firefly
    }

if __name__ == "__main__":
    print("ğŸš€ Persona System - Complete Demo")
    print("This demo showcases the full persona generation pipeline:")
    print("â€¢ Demographics â†’ Image â†’ Voice â†’ Interactive LLM")
    print()
    
    # Run complete demo
    asyncio.run(complete_persona_demo())
    
    # Show quick creation examples
    print(f"\n" + "=" * 60)
    print("âš¡ Quick Persona Creation Examples")
    
    # Example personas for different use cases
    examples = [
        ("Market Research", "Jennifer Walsh", 42, {
            "race_ethnicity": "white", 
            "gender": "female",
            "education": "college",
            "location_type": "rural",
            "income": "30k_50k"
        }),
        ("Tech Survey", "Alex Rivera", 28, {
            "race_ethnicity": "hispanic",
            "gender": "non-binary", 
            "education": "college",
            "location_type": "urban",
            "income": "50k_75k"
        })
    ]
    
    for use_case, name, age, demographics in examples:
        print(f"\nğŸ“Š {use_case} Persona:")
        result = asyncio.run(quick_persona_creation(name, age, demographics))
    
    print(f"\nğŸ’¡ Next Steps:")
    print("=" * 60)
    print("1. Set OPENAI_API_KEY for real generation")
    print("2. Use generated assets in research studies")
    print("3. Scale up with multiple personas")
    print("4. Integrate with survey platforms")
    print("5. Analyze behavioral patterns across demographics")
    
    print(f"\nğŸ‰ Demo complete! Ready for production use.")